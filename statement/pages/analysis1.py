# pages/analysis1.py
# -*- coding: utf-8 -*-

from __future__ import annotations

import re
from typing import Dict, List, Tuple

import pandas as pd
import streamlit as st
import plotly.graph_objects as go

from statement.pages.analysis1_config import IO_GUAN_GROUP, BS_GUAN_GROUP
from statement.pages.utils import list_data_files, year_from_filename, safe_numeric


# âœ… ì»¤ìŠ¤í…€ ì˜µì…˜ ì™„ì „ ë¹„í™œì„±í™”
CUSTOM_OPTIONS = {}
def series_cashsheet_row_total(unit_type: str, value_col: str) -> pd.DataFrame:
    """
    ìê¸ˆê³„ì‚°ì„œì—ì„œ 'ì ê¸ˆ ì§€ ì¶œ ì´ ê³„' í–‰ì„ ì°¾ì•„ value_col(ê²°ì‚°)ì„ ì—°ë„ë³„ë¡œ ê°€ì ¸ì˜´
    """
    files = list_data_files()
    rows = []

    for p in files:
        year_txt = year_from_filename(p.stem)
        try:
            year = int(year_txt)
        except Exception:
            continue

        try:
            path_str = str(p)
            sheet_map = _cached_sheet_map(path_str)
            sheet = sheet_map.get(("ìê¸ˆê³„ì‚°ì„œ", unit_type))
            if not sheet:
                continue

            df = _cached_read_sheet(path_str, sheet)
            subj = find_subject_col(df)

            if value_col not in df.columns:
                continue

            # ê³¼ëª©ëª… ì •ê·œí™”
            subj_norm = (
                df[subj].astype(str)
                .str.replace("\u00a0", " ", regex=False)
                .map(_norm)
            )

            # âœ… íƒ€ê²Ÿ í–‰ ì°¾ê¸°
            hit_idx = subj_norm[subj_norm == TARGET_TOTAL_LABEL_NORM].index
            if len(hit_idx) == 0:
                continue

            idx = int(hit_idx[-1])  # í˜¹ì‹œ ì—¬ëŸ¬ ê°œë©´ ë§ˆì§€ë§‰
            val = safe_numeric(df.loc[[idx], value_col]).iloc[0]
            if pd.isna(val):
                continue

            rows.append({"ì—°ë„": year, "ê¸ˆì•¡": float(val)})

        except Exception:
            continue

    if not rows:
        return pd.DataFrame(columns=["ì—°ë„", "ê¸ˆì•¡"])

    return pd.DataFrame(rows).sort_values("ì—°ë„")

# ======================================================
# ìºì‹œ: Excel ë°˜ë³µ ì½ê¸° ë°©ì§€
# ======================================================
@st.cache_data(show_spinner=False)
def _cached_sheet_map(path_str: str) -> dict[tuple[str, str], str]:
    xls = pd.ExcelFile(path_str)
    return parse_statement_sheets(xls.sheet_names)


@st.cache_data(show_spinner=False)
def _cached_read_sheet(path_str: str, sheet_name: str) -> pd.DataFrame:
    return pd.read_excel(path_str, sheet_name=sheet_name)

def series_cashsheet_last_row_total(unit_type: str, value_col: str) -> pd.DataFrame:
    """
    ìê¸ˆê³„ì‚°ì„œ(ë‹¨ìœ„: ì „ì²´/ë“±ë¡ê¸ˆ/ë¹„ë“±ë¡ê¸ˆ)ì—ì„œ
    'ë§¨ ì•„ë˜(ë§ˆì§€ë§‰ í–‰)'ì˜ value_col(ê²°ì‚°)ì„ ì—°ë„ë³„ë¡œ ê°€ì ¸ì™€ ì´ê³„ë¡œ ì‚¬ìš©
    """
    files = list_data_files()
    rows = []

    for p in files:
        year_txt = year_from_filename(p.stem)
        try:
            year = int(year_txt)
        except Exception:
            continue

        try:
            path_str = str(p)
            sheet_map = _cached_sheet_map(path_str)
            sheet = sheet_map.get(("ìê¸ˆê³„ì‚°ì„œ", unit_type))
            if not sheet:
                continue

            df = _cached_read_sheet(path_str, sheet)
            if value_col not in df.columns:
                continue

            vals = safe_numeric(df[value_col])

            # âœ… ë§ˆì§€ë§‰ ìœ íš¨ ê°’(ë¹ˆì¹¸/NaN ì œì™¸)
            last = vals.dropna()
            if last.empty:
                continue

            last_val = float(last.iloc[-1])
            rows.append({"ì—°ë„": year, "ê¸ˆì•¡": last_val})

        except Exception:
            continue

    if not rows:
        return pd.DataFrame(columns=["ì—°ë„", "ê¸ˆì•¡"])

    out = pd.DataFrame(rows).sort_values("ì—°ë„")
    return out

# ======================================================
# ë“¤ì—¬ì“°ê¸°(ìŠ¤í˜ì´ìŠ¤) ê¸°ë°˜ ê´€/í•­/ëª©
# - ê´€: 0
# - í•­: 5
# - ëª©: 10 (ì´ìƒ)
# ======================================================
def _leading_spaces(text: str) -> int:
    if text is None:
        return 0
    s = str(text).replace("\u00a0", " ")
    n = 0
    for ch in s:
        if ch == " ":
            n += 1
        elif ch == "\t":
            n += 4
        else:
            break
    return n

def depth_rules(statement_type: str) -> Tuple[int, int, int]:
    return (0, 5, 10)

def _norm(s: str) -> str:
    return re.sub(r"\s+", "", str(s).replace("\u00a0", " ")).strip()

TARGET_TOTAL_LABEL_NORM = _norm("ì ê¸ˆ ì§€ ì¶œ ì´ ê³„")  # => "ìê¸ˆì§€ì¶œì´ê³„"

# ======================================================
# ì‹œíŠ¸ëª… íŒŒì„œ
# ======================================================
SHEET_PATTERN = re.compile(r"^\s*(ìê¸ˆê³„ì‚°ì„œ|ì¬ë¬´ìƒíƒœí‘œ|ìš´ì˜ê³„ì‚°ì„œ)\s*\(\s*(ì „ì²´|ë“±ë¡ê¸ˆ|ë¹„ë“±ë¡ê¸ˆ)\s*\)\s*$")

def parse_statement_sheets(sheet_names: List[str]) -> Dict[Tuple[str, str], str]:
    mapping: Dict[Tuple[str, str], str] = {}
    for name in sheet_names:
        m = SHEET_PATTERN.match(str(name))
        if m:
            stmt, unit = m.group(1), m.group(2)
            mapping[(stmt, unit)] = name
    return mapping

def find_subject_col(df: pd.DataFrame) -> str:
    candidates = ["ê³¼ëª©", "ê³„ì •", "í•­ëª©", "ê³¼ëª©ëª…", "ê³„ì •ê³¼ëª©", "ê³„ì •ëª…"]
    for c in df.columns:
        if str(c).strip() in candidates:
            return c
    for c in df.columns:
        txt = str(c)
        if any(k in txt for k in candidates):
            return c
    raise ValueError("ê³¼ëª©(ê³„ì •/í•­ëª©) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# ======================================================
# ìˆ˜ì…/ì§€ì¶œ(ë˜ëŠ” ìì‚°/ë¶€ì±„/ê¸°ë³¸ê¸ˆ) ë¶„ë¥˜
# ======================================================
@st.cache_data(show_spinner=False)
def _classify_io(statement_type: str, guan: str) -> str:
    g = (guan or "").strip()

    if statement_type in ("ìê¸ˆê³„ì‚°ì„œ", "ìš´ì˜ê³„ì‚°ì„œ"):
        if g in IO_GUAN_GROUP:
            return IO_GUAN_GROUP[g]
    elif statement_type == "ì¬ë¬´ìƒíƒœí‘œ":
        if g in BS_GUAN_GROUP:
            return BS_GUAN_GROUP[g]

    gn = g.replace(" ", "")
    income_kw = ["ìˆ˜ì…", "ìˆ˜ìµ", "ì „ì…ê¸ˆ", "ê¸°ë¶€ê¸ˆ", "ë³´ì¡°ê¸ˆ", "ë“±ë¡ê¸ˆ", "êµìœ¡ë¶€ëŒ€ìˆ˜ìµ", "ìš´ì˜ìˆ˜ìµ"]
    expense_kw = ["ì§€ì¶œ", "ë¹„ìš©", "ìš´ì˜ë¹„ìš©", "ê´€ë¦¬ìš´ì˜ë¹„", "êµìœ¡ë¹„", "ì—°êµ¬ë¹„", "ì¥í•™ê¸ˆ", "ì¼ë°˜ê´€ë¦¬ë¹„"]

    if any(k.replace(" ", "") in gn for k in income_kw):
        return "ìˆ˜ì…"
    if any(k.replace(" ", "") in gn for k in expense_kw):
        return "ì§€ì¶œ"
    return "ê¸°íƒ€"
# ì¬ë¬´ìƒíƒœí‘œ í•©ì„± ê´€ ì •ì˜
ASSET_TOTAL_GUANS = {
    _norm("ìœ ë™ìì‚°"),
    _norm("íˆ¬ìì™€ê¸°íƒ€ìì‚°"),
    _norm("ê³ ì •ìì‚°"),
}

LIABILITY_TOTAL_GUANS = {
    _norm("ìœ ë™ë¶€ì±„"),
    _norm("ê³ ì •ë¶€ì±„"),
}
# ======================================================
# ìµœì‹  íŒŒì¼(ìµœì‹ ì—°ë„)ì—ì„œ ê´€/ëª© ìˆœì„œ ì¶”ì¶œ â†’ ë“œë¡­ë‹¤ìš´ ìˆœì„œ ì•ˆì •í™”
# ======================================================
def _latest_file_path():
    files = list_data_files()
    pairs = []
    for p in files:
        ytxt = year_from_filename(p.stem)
        try:
            y = int(ytxt)
        except Exception:
            continue
        pairs.append((y, p))
    if not pairs:
        return None
    pairs.sort(key=lambda x: x[0], reverse=True)
    return str(pairs[0][1])

def get_guan_order_from_files(statement_type: str, unit_type: str) -> List[str]:
    guan_d, _, _ = depth_rules(statement_type)
    path_str = _latest_file_path()
    if not path_str:
        return []

    try:
        sheet_map = _cached_sheet_map(path_str)
        sheet = sheet_map.get((statement_type, unit_type))
        if not sheet:
            return []

        df = _cached_read_sheet(path_str, sheet)
        subj = find_subject_col(df)

        subjects_raw = (
            df[subj].astype(str)
            .str.replace("\u00a0", " ", regex=False)
            .str.rstrip()
        )

        seen = set()
        out: List[str] = []
        for raw in subjects_raw.tolist():
            if str(raw).strip() == "":
                continue
            if _leading_spaces(raw) == guan_d:
                name = str(raw).strip()
                key = _norm(name)
                if key and key not in seen:
                    seen.add(key)
                    out.append(name)
        return out
    except Exception:
        return []

def get_hang_order_from_files(statement_type: str, unit_type: str) -> List[str]:
    _, hang_d, mok_d = depth_rules(statement_type)
    path_str = _latest_file_path()
    if not path_str:
        return []

    try:
        sheet_map = _cached_sheet_map(path_str)
        sheet = sheet_map.get((statement_type, unit_type))
        if not sheet:
            return []

        df = _cached_read_sheet(path_str, sheet)
        subj = find_subject_col(df)

        subjects_raw = (
            df[subj].astype(str)
            .str.replace("\u00a0", " ", regex=False)
            .str.rstrip()
        )

        seen = set()
        out: List[str] = []
        for raw in subjects_raw.tolist():
            if str(raw).strip() == "":
                continue

            depth = _leading_spaces(raw)
            name = str(raw).strip()

            # âœ… í•­(= ì •í™•íˆ hang depth)ë§Œ
            if depth == hang_d:
                key = _norm(name)
                if key and key not in seen:
                    seen.add(key)
                    out.append(name)

            # (ì˜µì…˜) ëª©ìœ¼ë¡œ ë‚´ë ¤ê°€ë©´ í•­ ìˆ˜ì§‘ ë¡œì§ì— ì˜í–¥ ì—†ì§€ë§Œ,
            #       êµ³ì´ ëŠê³  ì‹¶ìœ¼ë©´ ì•„ë˜ì²˜ëŸ¼ ì¨ë„ ë©ë‹ˆë‹¤.
            # if depth >= mok_d: 
            #     continue

        return out
    except Exception:
        return []

def get_mok_order_from_files(statement_type: str, unit_type: str) -> List[str]:
    _, _, mok_d = depth_rules(statement_type)
    path_str = _latest_file_path()
    if not path_str:
        return []

    try:
        sheet_map = _cached_sheet_map(path_str)
        sheet = sheet_map.get((statement_type, unit_type))
        if not sheet:
            return []

        df = _cached_read_sheet(path_str, sheet)
        subj = find_subject_col(df)

        subjects_raw = (
            df[subj].astype(str)
            .str.replace("\u00a0", " ", regex=False)
            .str.rstrip()
        )

        seen = set()
        out: List[str] = []
        for raw in subjects_raw.tolist():
            if str(raw).strip() == "":
                continue
            if _leading_spaces(raw) >= mok_d:
                n = _norm(str(raw).strip())
                if n and n not in seen:
                    seen.add(n)
                    out.append(n)  # norm ì €ì¥
        return out
    except Exception:
        return []

# ======================================================
# ì‹œê³„ì—´ êµ¬ì¶•
# - ê¸°ë³¸: ëª© ë¼ì¸ë§Œ ì§‘ê³„
# - ì˜ˆì™¸(ìš”ì²­ì‚¬í•­): "ë¯¸ì‚¬ìš©ì „ê¸°ì´ì›”ìê¸ˆ", "ë¯¸ì‚¬ìš©ì°¨ê¸°ì´ì›”ìê¸ˆ"ì€ "ê´€ í—¤ë”í–‰ ê°’" ê·¸ëŒ€ë¡œ
#   => ê´€ ë¼ì¸ì—ì„œ mokë¥¼ ê´€ëª…ìœ¼ë¡œ ì±„ì›Œì„œ ì‚´ì•„ë‚¨ê²Œ ì²˜ë¦¬
# ======================================================
SPECIAL_GUAN_DIRECT = {"ë¯¸ì‚¬ìš©ì „ê¸°ì´ì›”ìê¸ˆ", "ë¯¸ì‚¬ìš©ì°¨ê¸°ì´ì›”ìê¸ˆ"}

def build_timeseries(statement_type: str, unit_type: str, value_col: str) -> pd.DataFrame:
    guan_d, hang_d, mok_d = depth_rules(statement_type)
    files = list_data_files()
    rows = []

    for p in files:
        year_txt = year_from_filename(p.stem)
        try:
            year = int(year_txt)
        except Exception:
            continue

        try:
            path_str = str(p)
            sheet_map = _cached_sheet_map(path_str)
            sheet = sheet_map.get((statement_type, unit_type))
            if not sheet:
                continue

            df = _cached_read_sheet(path_str, sheet)
            subj = find_subject_col(df)

            if value_col not in df.columns:
                continue

            vals = safe_numeric(df[value_col]).fillna(0)

            subjects_raw = (
                df[subj].astype(str)
                .str.replace("\u00a0", " ", regex=False)
                .str.rstrip()
            )

            tmp = pd.DataFrame({"ì—°ë„": year, "ê³¼ëª©_raw": subjects_raw, "ê¸ˆì•¡": vals})
            tmp = tmp[tmp["ê³¼ëª©_raw"].notna() & (tmp["ê³¼ëª©_raw"] != "")].copy()

            guan = ""
            hang = ""
            mok = ""
            guan_list, hang_list, mok_list = [], [], []

            for s in tmp["ê³¼ëª©_raw"].tolist():
                depth = _leading_spaces(s)
                name = str(s).strip()

                if depth == guan_d:
                    guan = name
                    hang = ""
                    mok = ""

                    # âœ… íŠ¹ìˆ˜ ê´€ì€ ê´€ í—¤ë”í–‰ ìì²´ë¥¼ ë°ì´í„°ë¡œ ì·¨ê¸‰
                    if name in SPECIAL_GUAN_DIRECT:
                        mok = name

                elif depth == hang_d:
                    hang = name
                    mok = ""

                elif depth >= mok_d:
                    mok = name

                guan_list.append(guan)
                hang_list.append(hang)
                mok_list.append(mok)

            tmp["ê´€"] = guan_list
            tmp["í•­"] = hang_list
            tmp["ëª©"] = mok_list
            tmp["êµ¬ë¶„"] = tmp["ê´€"].map(lambda x: _classify_io(statement_type, x))

            # âœ… ëª©ì´ ë¹ˆ í–‰ ì œê±° (íŠ¹ìˆ˜ ê´€ í—¤ë”í–‰ì€ ëª©ì´ ì±„ì›Œì ¸ì„œ ì‚´ì•„ë‚¨ìŒ)
            tmp = tmp[tmp["ëª©"].astype(str).str.strip() != ""].copy()

            rows.append(tmp[["ì—°ë„", "êµ¬ë¶„", "ê´€", "í•­", "ëª©", "ê¸ˆì•¡"]])

        except Exception:
            continue

    if not rows:
        return pd.DataFrame(columns=["ì—°ë„", "êµ¬ë¶„", "ê´€", "í•­", "ëª©", "ê¸ˆì•¡"])

    out = pd.concat(rows, ignore_index=True)
    out = out.groupby(["ì—°ë„", "êµ¬ë¶„", "ê´€", "í•­", "ëª©"], as_index=False, sort=False)["ê¸ˆì•¡"].sum()
    return out

# ======================================================
# í…Œë§ˆ/ìƒ‰
# ======================================================
COMMON_FONT = dict(family="Arial", size=18)

def _theme_base() -> str:
    try:
        return (st.get_option("theme.base") or "").lower()
    except Exception:
        return ""

def _font_color() -> str:
    return "black" if _theme_base() == "light" else "white"

def _colors():
    base = _theme_base()
    if base == "light":
        return {"pos": "#1f77b4", "neg": "#d62728", "grid": "rgba(0,0,0,0.15)", "zero": "rgba(0,0,0,0.35)"}
    return {"pos": "#4da3ff", "neg": "#ff6b6b", "grid": "rgba(255,255,255,0.18)", "zero": "rgba(255,255,255,0.35)"}

def apply_common_layout(fig: go.Figure, height: int = 700):
    cols = _colors()
    base = _theme_base()

    if base == "light":
        paper_bg = "white"
        plot_bg = "white"
        font_color = "black"
    else:
        paper_bg = "rgba(0,0,0,0)"
        plot_bg = "rgba(0,0,0,0)"
        font_color = "white"

    fig.update_layout(
        height=height,
        font={**COMMON_FONT, "color": font_color},
        paper_bgcolor=paper_bg,
        plot_bgcolor=plot_bg,
        margin=dict(t=90, r=60, l=80, b=60),
    )
    fig.update_xaxes(showgrid=False, zeroline=False)
    fig.update_yaxes(showgrid=True, gridcolor=cols["grid"], zeroline=True, zerolinecolor=cols["zero"])

# ======================================================
# ê·¸ë˜í”„
# ======================================================
def plot_recent_amount(recent: pd.DataFrame, title_label: str) -> go.Figure:
    fig = go.Figure()
    fc = _font_color()

    fig.add_trace(
        go.Bar(
            x=recent["ì—°ë„_str"],
            y=recent["ê¸ˆì•¡_ë°±ë§Œì›"],
            name="ê¸ˆì•¡(ë°±ë§Œì›)",
            text=recent["ê¸ˆì•¡_ë°±ë§Œì›"].map(lambda x: f"{x:,.0f} ë°±ë§Œì›"),
            textposition="outside",
            textfont=dict(family="Arial", size=22, color="black"),
            hovertemplate="%{x}ë…„<br>%{y:,.0f} ë°±ë§Œì›<extra></extra>",
        )
    )

    fig.update_layout(
        height=800,
        margin=dict(t=140, r=60, l=60, b=60),

        title=dict(
            text=f"{title_label} | ìµœê·¼ 5ê°œë…„",
            font=dict(family="Arial", size=24, color=fc),
            x=0.5,
            xanchor="center",
            y=0.98,
            yanchor="top",
        ),

        # âœ… Xì¶•
        xaxis=dict(
            type="category",
            title=dict(
                text="íšŒê³„ì—°ë„",
                font=dict(family="Arial", size=24)   # ğŸ”¥ ì—¬ê¸°ë¡œ ì´ë™
            ),
            tickfont=dict(family="Arial", size=24),
        ),

        # âœ… Yì¶•
        yaxis=dict(
            title=dict(
                text="ê¸ˆì•¡(ë°±ë§Œì›)",
                font=dict(family="Arial", size=24)   # ğŸ”¥ ì—¬ê¸°ë¡œ ì´ë™
            ),
            tickfont=dict(family="Arial", size=24),
            tickformat=",",
        ),

        showlegend=False,
    )
    apply_common_layout(fig)
    return fig

def plot_recent_pct(recent: pd.DataFrame) -> go.Figure:
    pct = recent.copy()
    cols = _colors()
    fc = _font_color()

    pct["pct_label"] = pct["ì¦ê°ë¥ _%"].map(
        lambda x: "" if pd.isna(x) else f"{'â–²' if x >= 0 else 'â–¼'} {abs(x):.2f}%"
    )

    max_abs_pct = pd.to_numeric(pct["ì¦ê°ë¥ _%"], errors="coerce").abs().max()
    if pd.isna(max_abs_pct):
        max_abs_pct = 0
    ylim = max(5, max_abs_pct * 1.3)

    fig = go.Figure()
    fig.add_bar(
        x=pct["ì—°ë„_str"],
        y=pct["ì¦ê°ë¥ _%"],
        text=pct["pct_label"],
        textposition="outside",
        textfont=dict(family="Arial", size=22, color="black"),
        marker_color=[cols["pos"] if (pd.notna(v) and v >= 0) else cols["neg"] for v in pct["ì¦ê°ë¥ _%"]],
        hovertemplate="%{x}ë…„<br>%{y:+.2f}%<extra></extra>",
    )
    fig.add_hline(y=0, line_color="gray", opacity=0.6)

    fig.update_layout(
        height=350,
        margin=dict(t=40, b=40, l=60, r=40),
        showlegend=False,

        xaxis=dict(
            type="category",
            title=dict(
                text="íšŒê³„ì—°ë„",
                font=dict(family="Arial", size=24)   # âœ… ì—¬ê¸°
            ),
            tickfont=dict(family="Arial", size=24),
        ),

        yaxis=dict(
            title=dict(
                text="ì¦ê°ë¥ (%)",
                font=dict(family="Arial", size=24)   # âœ… ì—¬ê¸°
            ),
            tickfont=dict(family="Arial", size=24),
            ticksuffix="%",
            range=[-ylim, ylim],
        ),
    )

    apply_common_layout(fig)
    return fig

# ======================================================
# í‘œ
# ======================================================
def render_table(series: pd.DataFrame):
    show_display = series.rename(
        columns={
            "ê¸ˆì•¡": "ê¸ˆì•¡(ì›)",
            "ê¸ˆì•¡_ë°±ë§Œì›": "ê¸ˆì•¡(ë°±ë§Œì›)",
            "ì¦ê°_ë°±ë§Œì›": "ì¦ê°(ë°±ë§Œì›)",
            "ì¦ê°ë¥ _%": "ì¦ê°ë¥ (%)",
        }
    ).copy()

    show_display["ê¸ˆì•¡(ì›)"] = show_display["ê¸ˆì•¡(ì›)"].map(lambda x: f"{x:,.0f}")
    show_display["ê¸ˆì•¡(ë°±ë§Œì›)"] = show_display["ê¸ˆì•¡(ë°±ë§Œì›)"].map(lambda x: f"{x:,.0f}")
    show_display["ì¦ê°(ë°±ë§Œì›)"] = show_display["ì¦ê°(ë°±ë§Œì›)"].map(lambda x: "" if pd.isna(x) else f"{x:,.0f}")
    show_display["ì¦ê°ë¥ (%)"] = show_display["ì¦ê°ë¥ (%)"].map(lambda x: "" if pd.isna(x) else f"{x:+.2f}%")

    st.dataframe(show_display[["ì—°ë„", "ê¸ˆì•¡(ì›)", "ê¸ˆì•¡(ë°±ë§Œì›)", "ì¦ê°(ë°±ë§Œì›)", "ì¦ê°ë¥ (%)"]], use_container_width=True)

# ======================================================
# ë Œë”(ë©”ì¸)
# ======================================================
def render():
    st.subheader("ğŸ“ˆ ì—°ë„ë³„ ì¦ê°")

    st.markdown(
        """
        <style>
        /* selectbox ì „ì²´ í´ë¦­ ì˜ì—­ */
        div[data-baseweb="select"] { cursor: pointer !important; }
        div[data-baseweb="select"] * { cursor: pointer !important; }
        </style>
        """,
        unsafe_allow_html=True,
    )
    
    def _section_open(title: str, desc: str = ""):
        st.markdown(
            f"""
            <div class="section-card">
            <div class="section-title">{title}</div>
            {"<div class='section-desc'>" + desc + "</div>" if desc else ""}
            """,
            unsafe_allow_html=True,
        )

    def _section_close():
        st.markdown("</div>", unsafe_allow_html=True)

    files = list_data_files()
    if not files:
        st.error("data/ í´ë”ì— ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # =========================
    # ì œí‘œ | ì¡°íšŒë‹¨ìœ„ | êµ¬ë¶„ | ì¡°íšŒêµ¬ë¶„ (í•œ ì¤„)
    # =========================
    c1, c2, c3, c4 = st.columns([1.2, 1.0, 1.2, 1.6])

    with c1:
        statement_type = st.radio(
            "ì œí‘œ",
            ["ìê¸ˆê³„ì‚°ì„œ", "ì¬ë¬´ìƒíƒœí‘œ", "ìš´ì˜ê³„ì‚°ì„œ"],
            horizontal=True,
            key="a1_stmt",
        )

    with c2:
        level = st.radio(
            "ì¡°íšŒ ë‹¨ìœ„",
            ["ê´€", "í•­", "ëª©"],
            horizontal=True,
            key="a1_level",
        )

    with c3:
        unit_type = st.radio(
            "êµ¬ë¶„",
            ["ì „ì²´", "ë“±ë¡ê¸ˆ", "ë¹„ë“±ë¡ê¸ˆ"],
            horizontal=True,
            key="a1_unit",
        )

    with c4:
        if statement_type == "ì¬ë¬´ìƒíƒœí‘œ":
            io_filter = st.radio(
                "ì¡°íšŒ êµ¬ë¶„",
                ["ì „ì²´", "ìì‚°", "ë¶€ì±„/ê¸°ë³¸ê¸ˆ"],
                horizontal=True,
                key="a1_io",
            )
        else:
            io_filter = st.radio(
                "ì¡°íšŒ êµ¬ë¶„",
                ["ì „ì²´", "ìˆ˜ì…", "ì§€ì¶œ"],
                horizontal=True,
                key="a1_io",
            )
    st.divider()
    # =========================
    # ë°ì´í„° êµ¬ì¶•
    # =========================
    value_col = "ë‹¹ê¸°" if statement_type in ("ì¬ë¬´ìƒíƒœí‘œ", "ìš´ì˜ê³„ì‚°ì„œ") else "ê²°ì‚°"

    ts = build_timeseries(statement_type, unit_type, value_col)
    if ts.empty:
        st.error("ì„ íƒí•œ ì¡°ê±´ìœ¼ë¡œ ëª¨ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (íŒŒì¼/ì‹œíŠ¸ëª… ê·œì¹™ í™•ì¸)")
        st.stop()

    if statement_type != "ì¬ë¬´ìƒíƒœí‘œ" and io_filter in ("ìˆ˜ì…", "ì§€ì¶œ"):
        ts = ts[ts["êµ¬ë¶„"] == io_filter].copy()
        if ts.empty:
            st.warning(f"'{io_filter}'ìœ¼ë¡œ í•„í„°ë§í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

    ts = ts.copy()
    ts["ê´€_norm"] = ts["ê´€"].map(_norm)
    ts["í•­_norm"] = ts["í•­"].map(_norm)
    ts["ëª©_norm"] = ts["ëª©"].map(_norm)

    # =========================
    # 0ì› ì œì™¸ìš©
    # =========================
    def _nonzero_norms(df: pd.DataFrame, col_norm: str) -> set[str]:
        s = df.groupby(col_norm, as_index=False)["ê¸ˆì•¡"].sum()
        return set(s.loc[s["ê¸ˆì•¡"].abs() > 0, col_norm])

    nonzero_guans = _nonzero_norms(ts, "ê´€_norm")
    nonzero_hangs = _nonzero_norms(ts[ts["í•­_norm"].astype(str).str.strip() != ""], "í•­_norm")
    nonzero_moks = _nonzero_norms(ts, "ëª©_norm")

    # =========================
    # ëª© ì˜µì…˜
    # =========================
    EXCLUDE_MOKS = {
        _norm("ìœ ë™ìê¸ˆ"),
        _norm("ê¸°íƒ€ìœ ë™ìì‚°"),
        _norm("ì˜ˆìˆ˜ê¸ˆ"),
        _norm("ì„ ìˆ˜ê¸ˆ"),
        _norm("ê¸°íƒ€ìœ ë™ë¶€ì±„"),
    }
    valid_mok_norms = {n for n in nonzero_moks if n and n not in EXCLUDE_MOKS}

    mok_order = get_mok_order_from_files(statement_type, unit_type)
    ordered_norms = [n for n in mok_order if n in valid_mok_norms]
    ordered_set = set(ordered_norms)

    rest_norms = []
    seen = set()
    for n in ts["ëª©_norm"].tolist():
        if n in valid_mok_norms and n not in ordered_set and n not in seen:
            seen.add(n)
            rest_norms.append(n)

    final_mok_norms = ordered_norms + rest_norms

    norm_to_label = dict(
        ts.loc[ts["ëª©_norm"].isin(valid_mok_norms), ["ëª©_norm", "ëª©"]]
        .drop_duplicates(subset=["ëª©_norm"])
        .itertuples(index=False, name=None)
    )

    MOK_OPTIONS = [
        {"id": f"MOK__{n}", "label": norm_to_label.get(n, n), "kind": "direct_mok", "match_mok_norm": n}
        for n in final_mok_norms
    ]

    # =========================
    # ê´€/í•­ ì˜µì…˜
    # =========================
    def _ordered_unique(seq):
        out = []
        seen = set()
        for x in seq:
            s = str(x).strip()
            if not s or s in seen:
                continue
            seen.add(s)
            out.append(s)
        return out

    guan_order = get_guan_order_from_files(statement_type, unit_type)
    hang_order = get_hang_order_from_files(statement_type, unit_type)

    def build_guan_options(df: pd.DataFrame) -> list[dict]:
        guans_ts = _ordered_unique(df["ê´€"].tolist())
        latest_set = set(guan_order)
        guans_latest = [g for g in guan_order if g in set(guans_ts)]
        rest = [g for g in guans_ts if g not in latest_set]
        guans = guans_latest + rest

        out = []
        for g in guans:
            gnorm = _norm(g)
            if gnorm not in nonzero_guans:
                continue

            if io_filter != "ì „ì²´":
                if statement_type in ("ìê¸ˆê³„ì‚°ì„œ", "ìš´ì˜ê³„ì‚°ì„œ"):
                    if IO_GUAN_GROUP.get(g, "ê¸°íƒ€") != io_filter:
                        continue
                elif statement_type == "ì¬ë¬´ìƒíƒœí‘œ":
                    if BS_GUAN_GROUP.get(g, "ê¸°íƒ€") != io_filter:
                        continue

            out.append({"id": f"GUAN__{g}", "label": g, "kind": "direct_guan", "match_guan": g})
        return out

    def build_hang_options(df: pd.DataFrame) -> list[dict]:
        # tsì— ì¡´ì¬í•˜ëŠ” í•­(ë“±ì¥ìˆœì„œ)
        hangs_ts = _ordered_unique(df["í•­"].tolist())
        hangs_ts_norm = {_norm(h) for h in hangs_ts if _norm(h)}

        # âœ… ìµœì‹  ì‹œíŠ¸ ìˆœì„œ ìš°ì„  + ë‚˜ë¨¸ì§€(ë“±ì¥ìˆœì„œ)
        hangs_latest = [h for h in hang_order if _norm(h) in hangs_ts_norm]
        latest_norm_set = {_norm(h) for h in hangs_latest}

        rest = [h for h in hangs_ts if _norm(h) and _norm(h) not in latest_norm_set]
        hangs = hangs_latest + rest

        out = []
        for h in hangs:
            hn = _norm(h)
            if not hn:
                continue
            if hn not in nonzero_hangs:
                continue
            out.append({"id": f"HANG__{h}", "label": h, "kind": "direct_hang", "match_hang": h})
        return out

    GUAN_OPTIONS = build_guan_options(ts)
    # âœ… ê´€ ë‹¨ìœ„ ë“œë¡­ë‹¤ìš´ ë§¨ ì•„ë˜ì— "ì´ê³„" ì˜µì…˜ ì¶”ê°€
    if statement_type == "ìê¸ˆê³„ì‚°ì„œ" and level == "ê´€" and io_filter == "ì „ì²´":
        GUAN_OPTIONS.append({
            "id": "GUAN__TOTAL_CASH_OUT",
            "label": "ì´ ê³„",
            "kind": "cash_total_row",
        }) 
    # âœ… ì¬ë¬´ìƒíƒœí‘œ ê´€ ë‹¨ìœ„ì—ì„œ í•©ì„± ê´€ ì¶”ê°€
    if statement_type == "ì¬ë¬´ìƒíƒœí‘œ" and level == "ê´€":
        GUAN_OPTIONS.append({
            "id": "GUAN__ASSET_TOTAL",
            "label": "ìì‚°ì´ê³„",
            "kind": "asset_total",
        })
        GUAN_OPTIONS.append({
            "id": "GUAN__LIABILITY_TOTAL",
            "label": "ë¶€ì±„ì´ê³„",
            "kind": "liability_total",
        })
    HANG_OPTIONS = build_hang_options(ts)

    # =========================
    # ì˜µì…˜ id ë§µ + ì‹œê³„ì—´ ì§‘ê³„
    # =========================
    opt_by_id = {x["id"]: x for x in GUAN_OPTIONS}
    opt_by_id.update({x["id"]: x for x in HANG_OPTIONS})
    opt_by_id.update({x["id"]: x for x in MOK_OPTIONS})

    def series_from_direct_guan(match_guan: str) -> pd.DataFrame:
        gnorm = _norm(match_guan)
        special_norms = {_norm(x) for x in SPECIAL_GUAN_DIRECT}

        if gnorm in special_norms:
            sub = ts[
                (ts["ê´€_norm"] == gnorm)
                & (ts["í•­_norm"] == "")
                & (ts["ëª©_norm"] == gnorm)
            ].copy()
        else:
            sub = ts[ts["ê´€_norm"] == gnorm].copy()

        if sub.empty:
            return pd.DataFrame(columns=["ì—°ë„", "ê¸ˆì•¡"])
        return sub.groupby("ì—°ë„", as_index=False)["ê¸ˆì•¡"].sum().sort_values("ì—°ë„")
    
    def series_asset_total() -> pd.DataFrame:
        sub = ts[ts["ê´€_norm"].isin(ASSET_TOTAL_GUANS)].copy()
        if sub.empty:
            return pd.DataFrame(columns=["ì—°ë„", "ê¸ˆì•¡"])
        return sub.groupby("ì—°ë„", as_index=False)["ê¸ˆì•¡"].sum().sort_values("ì—°ë„")


    def series_liability_total() -> pd.DataFrame:
        sub = ts[ts["ê´€_norm"].isin(LIABILITY_TOTAL_GUANS)].copy()
        if sub.empty:
            return pd.DataFrame(columns=["ì—°ë„", "ê¸ˆì•¡"])
        return sub.groupby("ì—°ë„", as_index=False)["ê¸ˆì•¡"].sum().sort_values("ì—°ë„")

    def series_from_direct_hang(match_hang: str) -> pd.DataFrame:
        hnorm = _norm(match_hang)
        sub = ts[ts["í•­_norm"] == hnorm].copy()
        if sub.empty:
            return pd.DataFrame(columns=["ì—°ë„", "ê¸ˆì•¡"])
        return sub.groupby("ì—°ë„", as_index=False)["ê¸ˆì•¡"].sum().sort_values("ì—°ë„")
    def series_total_cash_out() -> pd.DataFrame:
        # âœ… ìê¸ˆê³„ì‚°ì„œ ì§€ì¶œ ì „ì²´ë¥¼ ì—°ë„ë³„ í•©ì‚°
        sub = ts[ts["êµ¬ë¶„"] == "ì§€ì¶œ"].copy()
        if sub.empty:
            return pd.DataFrame(columns=["ì—°ë„", "ê¸ˆì•¡"])
        return sub.groupby("ì—°ë„", as_index=False)["ê¸ˆì•¡"].sum().sort_values("ì—°ë„")

    _cache: Dict[str, pd.DataFrame] = {}

    def get_series(option_id: str) -> pd.DataFrame:
        if option_id in _cache:
            return _cache[option_id]

        o = opt_by_id[option_id]
        kind = o.get("kind")

        # âœ… ìê¸ˆê³„ì‚°ì„œ 'ì ê¸ˆ ì§€ ì¶œ ì´ ê³„' í–‰ ì§ì ‘ ì¶”ì¶œ
        if kind == "cash_total_row":
            res = series_cashsheet_row_total(unit_type, value_col)

        # âœ… ì¬ë¬´ìƒíƒœí‘œ í•©ì„± ê´€
        elif kind == "asset_total":
            res = series_asset_total()

        elif kind == "liability_total":
            res = series_liability_total()

        # âœ… ê¸°ì¡´ ë¡œì§
        elif kind == "direct_guan":
            res = series_from_direct_guan(o["match_guan"])

        elif kind == "direct_hang":
            res = series_from_direct_hang(o["match_hang"])

        elif kind == "direct_mok":
            sub = ts[ts["ëª©_norm"] == o["match_mok_norm"]].copy()
            res = (
                sub.groupby("ì—°ë„", as_index=False)["ê¸ˆì•¡"].sum().sort_values("ì—°ë„")
                if not sub.empty
                else pd.DataFrame(columns=["ì—°ë„", "ê¸ˆì•¡"])
            )

        else:
            res = pd.DataFrame(columns=["ì—°ë„", "ê¸ˆì•¡"])

        _cache[option_id] = res
        return res

    # =========================
    # âœ… ë‹¨ì¼ ì„ íƒë°•ìŠ¤ â€” ì „ì²´ í­ ì‚¬ìš©
    # =========================
    if level == "ê´€":
        labels = [x["label"] for x in GUAN_OPTIONS if not x.get("hidden")]
        by_label = {x["label"]: x for x in GUAN_OPTIONS if not x.get("hidden")}
        box_label = "ê´€ ì„ íƒ"
    elif level == "í•­":
        labels = [x["label"] for x in HANG_OPTIONS]
        by_label = {x["label"]: x for x in HANG_OPTIONS}
        box_label = "í•­ ì„ íƒ"
    else:
        labels = [x["label"] for x in MOK_OPTIONS]
        by_label = {x["label"]: x for x in MOK_OPTIONS}
        box_label = "ëª© ì„ íƒ"

    if not labels:
        st.warning("ì„ íƒ ê°€ëŠ¥í•œ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. (í•„í„° ì¡°ê±´ì„ í™•ì¸í•˜ì„¸ìš”)")
        st.stop()

    # âœ… (1) í•­ëª©ì„ íƒ ì„¹ì…˜ ë°•ìŠ¤
    _section_open("ğŸ” í•­ëª© ì„ íƒ", "ì¡°íšŒ ë‹¨ìœ„ì— ë§ëŠ” í•­ëª©ì„ ì„ íƒí•˜ë©´ ì•„ë˜ì—ì„œ ìš”ì•½â†’ê·¸ë˜í”„â†’í‘œë¡œ ì´ì–´ì§‘ë‹ˆë‹¤.")
    sel_label = st.selectbox(box_label, labels, key=f"a1_single_select_{level}")
    sel = by_label[sel_label]
    title_label = f"{sel_label} ({level})"
    st.caption(f"ì„ íƒ: **{title_label}**")
    _section_close()

    st.divider()

    # =========================
    # ì´í›„ ë™ì¼(ê·¸ë˜í”„/í‘œ)
    # =========================
    series = get_series(sel["id"])
    if series.empty:
        st.warning("ì„ íƒí•œ í•­ëª©ì— ëŒ€í•´ í•©ì‚° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    series = series.copy()
    series["ì—°ë„"] = series["ì—°ë„"].astype(int)
    series = series.sort_values("ì—°ë„").reset_index(drop=True)
    series["ê¸ˆì•¡_ë°±ë§Œì›"] = series["ê¸ˆì•¡"] / 1_000_000
    series["ì¦ê°_ë°±ë§Œì›"] = series["ê¸ˆì•¡_ë°±ë§Œì›"].diff()
    series["ì¦ê°ë¥ _%"] = series["ê¸ˆì•¡_ë°±ë§Œì›"].pct_change() * 100

    recent = series.tail(5).copy()
    recent["ì—°ë„_str"] = recent["ì—°ë„"].astype(str)

    # âœ… (3) ê·¸ë˜í”„ ì„¹ì…˜ ë°•ìŠ¤
    _section_open("ğŸ“Š ì¶”ì´ ê·¸ë˜í”„", "ìµœê·¼ 5ê°œë…„ ê¸ˆì•¡ê³¼ ì¦ê°ë¥ ì„ í•¨ê»˜ ë´…ë‹ˆë‹¤.")

    st.markdown("### ğŸ•” ìµœê·¼ 5ê°œë…„ ë¹„êµ (ê¸ˆì•¡)")
    st.plotly_chart(plot_recent_amount(recent, title_label), use_container_width=True)

    st.markdown("### ğŸ“‰ ì „ë…„ ëŒ€ë¹„ ì¦ê°ë¥ ")
    st.plotly_chart(plot_recent_pct(recent), use_container_width=True)

    _section_close()

    st.divider()

    # âœ… (4) í‘œ ì„¹ì…˜ ë°•ìŠ¤
    _section_open("ğŸ“‹ ë°ì´í„° í‘œ", "ì—°ë„ë³„ ê¸ˆì•¡/ì¦ê°/ì¦ê°ë¥ ì„ í‘œë¡œ í™•ì¸í•©ë‹ˆë‹¤.")
    render_table(series)
    _section_close()
