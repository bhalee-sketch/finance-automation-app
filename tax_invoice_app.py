# tax_invoice_app.py
# -*- coding: utf-8 -*-

import os
from io import BytesIO

import pandas as pd
import streamlit as st
from openpyxl.utils import get_column_letter


# =========================== ê³µí†µ ìœ í‹¸ ===========================

def normalize_key(series: pd.Series) -> pd.Series:
    """ì‚¬ì—…ìë²ˆí˜¸ ë¹„êµë¥¼ ìœ„í•´ ìˆ«ìë§Œ ë‚¨ê¸°ëŠ” ì •ê·œí™”"""
    return series.astype(str).str.replace(r"[^0-9]", "", regex=True).str.strip()


def detect_key_index(header_row, candidates):
    """í—¤ë”ì—ì„œ íŠ¹ì • ë¬¸ìì—´ í¬í•¨ ì»¬ëŸ¼ index ì°¾ê¸°"""
    for idx, val in enumerate(header_row):
        txt = str(val)
        for c in candidates:
            if c in txt:
                return idx
    return None


def find_col(df: pd.DataFrame, keywords):
    """í•´ë‹¹ í‚¤ì›Œë“œë¥¼ ê°€ì§„ ì»¬ëŸ¼ì˜ ì—‘ì…€ index(1ë¶€í„°)ë¥¼ ì°¾ê¸°"""
    for col in df.columns:
        s = str(col)
        for kw in keywords:
            if kw in s:
                return df.columns.get_loc(col) + 1
    return None


def pick_col_name(df: pd.DataFrame, keywords):
    """í‚¤ì›Œë“œ í¬í•¨ ì»¬ëŸ¼ëª…ì„ ë°˜í™˜"""
    for col in df.columns:
        s = str(col)
        for kw in keywords:
            if kw in s:
                return col
    return None


def sanitize_headers(header_row):
    """NaN, ì¤‘ë³µ ì»¬ëŸ¼ëª… ì •ë¦¬"""
    new_headers = []
    used = {}
    for i, h in enumerate(header_row):
        if pd.isna(h) or str(h).strip() == "":
            base = f"Unnamed_{i+1}"
        else:
            base = str(h)

        if base in used:
            used[base] += 1
            name = f"{base}_{used[base]}"
        else:
            used[base] = 1
            name = base

        new_headers.append(name)

    return new_headers


def align_columns(ref_df, target_df):
    """ë§¤ì…ì‹œíŠ¸ ì»¬ëŸ¼ ìˆœì„œë¥¼ ë§¤ì¶œê³¼ ë™ì¼í•˜ê²Œ ì •ë ¬"""
    if ref_df.empty or target_df.empty:
        return target_df

    ref_cols = list(ref_df.columns)
    for c in ref_cols:
        if c not in target_df.columns:
            target_df[c] = pd.NA

    return target_df[ref_cols]


# =========================== ë§¤ì… ì „ìš© ì •ë¦¬ ===========================

def clean_buy_df(df):
    """
    ë§¤ì… ì „ìš© ì •ë¦¬:
    - ê³µê¸‰ë°›ëŠ”ìë“±ë¡ë²ˆí˜¸ ì œê±°
    - ê³µê¸‰ìë“±ë¡ë²ˆí˜¸(Bì—´)ë¡œ ì¬ë°°ì¹˜
    """
    if df.empty:
        return df

    cols = list(df.columns)

    # ê³µê¸‰ë°›ëŠ”ìë“±ë¡ë²ˆí˜¸ ì œê±°
    remove_cols = []
    for c in cols:
        s = str(c)
        if "ê³µê¸‰ë°›ëŠ”ìë“±ë¡ë²ˆí˜¸" in s or ("ê³µê¸‰ë°›ëŠ”ì" in s and "ë“±ë¡ë²ˆí˜¸" in s):
            remove_cols.append(c)

    for c in remove_cols:
        if c in cols:
            cols.remove(c)

    # ê³µê¸‰ìë“±ë¡ë²ˆí˜¸ â†’ Bì—´ ë°°ì¹˜
    supplier = None
    for c in cols:
        if "ê³µê¸‰ìë“±ë¡ë²ˆí˜¸" in str(c):
            supplier = c
            break

    if supplier:
        cols.remove(supplier)
        cols.insert(1, supplier)

    return df[cols]


# =========================== ê³µí†µ ì •ë¦¬ ===========================

def clean_common_df(df):
    """
    ë§¤ì…/ë§¤ì¶œ ê³µí†µ ì •ë¦¬:
    - Unnamed ì‚­ì œ
    - ì—…íƒœ/ì¢…ëª© ì‚­ì œ
    - ì‚¬ì—…ìë²ˆí˜¸, ê±°ë˜ì²˜ëª…, ë°œìƒê¸ˆì•¡ ì‚­ì œ
    - ë§¤ìˆ˜_y, ê³µê¸‰ê°€ì•¡_y, ë¶€ê°€ì„¸ì•¡ ì‚­ì œ
    - _dup ì»¬ëŸ¼ ì‚­ì œ
    """
    if df.empty:
        return df

    drop_cols = []
    for c in df.columns:
        s = str(c)
        if s.startswith("Unnamed_"):
            drop_cols.append(c)
        elif "ì—…íƒœ" in s or "ì¢…ëª©" in s:
            drop_cols.append(c)
        # ğŸ”½ ì—¬ê¸° ì¤„ë§Œ ì¶”ê°€í–ˆë‹¤ê³  ë³´ë©´ ë¨
        elif s in ["ì‚¬ì—…ìë²ˆí˜¸", "ê±°ë˜ì²˜ëª…", "ë°œìƒê¸ˆì•¡",
                   "ë§¤ìˆ˜_y", "ê³µê¸‰ê°€ì•¡_y", "ë¶€ê°€ì„¸ì•¡"]:
            drop_cols.append(c)
        elif s.endswith("_dup"):
            drop_cols.append(c)

    if drop_cols:
        df = df.drop(columns=drop_cols)

    return df


# =========================== í•™ì‚¬ ê±°ë˜ì²˜ëª… ì¬ë°°ì¹˜ ===========================

def reorder_haksa_vendor(df):
    """ì‚¬ì—…ìë²ˆí˜¸_í•™ì‚¬ ë°”ë¡œ ì˜¤ë¥¸ìª½ì— ê±°ë˜ì²˜ëª…_í•™ì‚¬ ë°°ì¹˜"""
    if df.empty:
        return df

    cols = list(df.columns)

    if "ì‚¬ì—…ìë²ˆí˜¸_í•™ì‚¬" in cols and "ê±°ë˜ì²˜ëª…_í•™ì‚¬" in cols:
        cols.remove("ê±°ë˜ì²˜ëª…_í•™ì‚¬")
        idx = cols.index("ì‚¬ì—…ìë²ˆí˜¸_í•™ì‚¬")
        cols.insert(idx + 1, "ê±°ë˜ì²˜ëª…_í•™ì‚¬")
        df = df[cols]

    return df


# =========================== íŒŒì¼ ì½ê¸° ===========================

def import_by_pattern(uploaded_files, pattern, start_row_first):
    processed = 0
    skipped = 0
    first = True
    df_list = []

    for f in uploaded_files:
        if pattern in f.name:
            ext = os.path.splitext(f.name)[1].lower()
            if ext == ".xls":
                st.warning(f"{f.name}ì€ XLSë¼ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
                skipped += 1
                continue

            try:
                f.seek(0)
                raw = pd.read_excel(
                    f,
                    header=None,
                    engine="openpyxl",
                    dtype=str,
                    na_filter=False,        # âœ… ë¹ˆì¹¸/ë§ˆìŠ¤í‚¹ì„ NaNìœ¼ë¡œ ëœ ë°”ê¿ˆ
                    keep_default_na=False
                )

            except Exception as e:
                st.warning(f"{f.name} ì½ê¸° ì˜¤ë¥˜: {e}")
                skipped += 1
                continue

            if len(raw) < start_row_first:
                skipped += 1
                continue

            start = start_row_first - 1 if first else start_row_first
            if len(raw) <= start:
                skipped += 1
                continue

            df_list.append(raw.iloc[start:].copy())
            processed += 1
            first = False

    df = pd.concat(df_list, ignore_index=True) if df_list else pd.DataFrame()
    return df, f"{pattern} â†’ ì²˜ë¦¬ {processed}ê±´ / ê±´ë„ˆëœ€ {skipped}ê±´"


# =========================== ë§¤ì¹­ ë¡œì§ ===========================

def connect_by_id(home_df, haksa_df):
    if home_df.empty:
        return pd.DataFrame()

    # í™ˆíƒìŠ¤ í—¤ë”/ë³¸ë¬¸
    home_header = sanitize_headers(list(home_df.iloc[0]))
    home_body = home_df.iloc[1:].reset_index(drop=True)
    home_body.columns = home_header

    # í•™ì‚¬ í—¤ë”/ë³¸ë¬¸
    if not haksa_df.empty:
        haksa_header = sanitize_headers(list(haksa_df.iloc[0]))
        haksa_body = haksa_df.iloc[1:].reset_index(drop=True)
        haksa_body.columns = haksa_header
    else:
        haksa_body = pd.DataFrame()

    # í™ˆíƒìŠ¤ í‚¤ í‘œì¤€í™”
    key_idx = detect_key_index(home_header, ["ê³µê¸‰ìë“±ë¡ë²ˆí˜¸", "ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸"])
    if key_idx is None:
        key_idx = 1

    key_col = home_body.columns[key_idx]
    if "ê³µê¸‰ìë“±ë¡ë²ˆí˜¸" not in str(key_col):
        home_body["ê³µê¸‰ìë“±ë¡ë²ˆí˜¸"] = home_body[key_col]
    else:
        if key_col != "ê³µê¸‰ìë“±ë¡ë²ˆí˜¸":
            home_body["ê³µê¸‰ìë“±ë¡ë²ˆí˜¸"] = home_body[key_col]

    # í™ˆíƒìŠ¤ ê¸ˆì•¡ í‘œì¤€í™”
    sup = pick_col_name(home_body, ["ê³µê¸‰ê°€ì•¡"])
    if sup:
        home_body["ê³µê¸‰ê°€ì•¡"] = home_body[sup]

    tax = pick_col_name(home_body, ["ì„¸ì•¡"])
    if tax:
        home_body["ì„¸ì•¡"] = home_body[tax]

    tot = pick_col_name(home_body, ["í•©ê³„ê¸ˆì•¡", "ë°œìƒê¸ˆì•¡"])
    if tot:
        home_body["í•©ê³„ê¸ˆì•¡"] = home_body[tot]

    # í•™ì‚¬ í‘œì¤€í™”
    if not haksa_body.empty:
        key_h = pick_col_name(haksa_body, ["ì‚¬ì—…ìë²ˆí˜¸"])
        haksa_body["ì‚¬ì—…ìë²ˆí˜¸_í•™ì‚¬"] = haksa_body[key_h]

        sup_h = pick_col_name(haksa_body, ["ê³µê¸‰ê°€ì•¡"])
        if sup_h:
            haksa_body["ê³µê¸‰ê°€ì•¡_í•™ì‚¬"] = haksa_body[sup_h]

        tax_h = pick_col_name(haksa_body, ["ì„¸ì•¡"])
        if tax_h:
            haksa_body["ì„¸ì•¡_í•™ì‚¬"] = haksa_body[tax_h]

        tot_h = pick_col_name(haksa_body, ["í•©ê³„ê¸ˆì•¡", "ë°œìƒê¸ˆì•¡"])
        if tot_h:
            haksa_body["í•©ê³„ê¸ˆì•¡_í•™ì‚¬"] = haksa_body[tot_h]

        # í•™ì‚¬ ê±°ë˜ì²˜ëª…
        vendor_h = pick_col_name(haksa_body, ["ê±°ë˜ì²˜ëª…", "ìƒí˜¸"])
        if vendor_h:
            haksa_body["ê±°ë˜ì²˜ëª…_í•™ì‚¬"] = haksa_body[vendor_h]

        # ë¨¸ì§€
        home_body["__KEY"] = normalize_key(home_body["ê³µê¸‰ìë“±ë¡ë²ˆí˜¸"])
        haksa_body["__KEY"] = normalize_key(haksa_body["ì‚¬ì—…ìë²ˆí˜¸_í•™ì‚¬"])

        # âœ… mergeëŠ” í•œ ë²ˆë§Œ (indicator í¬í•¨)
        merged = pd.merge(
            home_body,
            haksa_body,
            on="__KEY",
            how="left",
            indicator=True
        )

        # âœ… í™ˆíƒìŠ¤ì— ì—†ëŠ” í•™ì‚¬ í‚¤ë§Œ ì¶”ì¶œ
        home_keys = set(home_body["__KEY"].dropna().astype(str))
        haksa_only = haksa_body[
            haksa_body["__KEY"].notna() &
            ~haksa_body["__KEY"].astype(str).isin(home_keys)
        ].copy()

        if not haksa_only.empty:
            # merged êµ¬ì¡°ì— ë§ê²Œ ì»¬ëŸ¼ ë³´ì •
            for c in merged.columns:
                if c not in haksa_only.columns and c != "_merge":
                    haksa_only[c] = pd.NA

            # ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸°
            haksa_only = haksa_only[[c for c in merged.columns if c != "_merge"]]
            haksa_only["_merge"] = "haksa_only"

            merged = pd.concat([merged, haksa_only], ignore_index=True)

        # ë§ˆë¬´ë¦¬ ì •ë¦¬
        merged = merged.drop(columns=["__KEY", "_merge"])
    
    else:
        merged = home_body.copy()

    return merged


# =========================== ì—‘ì…€ ìˆ˜ì‹ ===========================

def display_len(cell) -> int:
    v = cell.value
    if v is None:
        return 0

    if isinstance(v, bool):
        return 4 if v else 5  # TRUE / FALSE

    if isinstance(v, (int, float)):
        fmt = cell.number_format or ""
        if "," in fmt:
            try:
                return len(f"{v:,.0f}")
            except Exception:
                return len(str(v))
        return len(str(v))

    return len(str(v))

def apply_formulas_and_autofit(writer, sheet, df, is_tax=True):
    ws = writer.book[sheet]
    start_row = 2

    col_B = find_col(df, ["ê³µê¸‰ìë“±ë¡ë²ˆí˜¸"])
    col_E = find_col(df, ["ê³µê¸‰ê°€ì•¡"])
    col_F = find_col(df, ["ì„¸ì•¡"])
    col_G = find_col(df, ["í•©ê³„ê¸ˆì•¡"])
    col_K = find_col(df, ["ì‚¬ì—…ìë²ˆí˜¸_í•™ì‚¬"])
    col_P = find_col(df, ["ê³µê¸‰ê°€ì•¡_í•™ì‚¬"])
    col_Q = find_col(df, ["ì„¸ì•¡_í•™ì‚¬"])
    col_R = find_col(df, ["í•©ê³„ê¸ˆì•¡_í•™ì‚¬"])

    col_W = df.shape[1] + 1
    col_X = col_W + 1
    col_Y = col_W + 2
    col_Z = col_W + 3

    ws.cell(1, col_W).value = "ì‚¬ì—…ìë²ˆí˜¸ì¼ì¹˜"
    if is_tax:
        ws.cell(1, col_X).value = "ê³µê¸‰ê°€ì•¡ì°¨ì´"
        ws.cell(1, col_Y).value = "ì„¸ì•¡ì°¨ì´"
        ws.cell(1, col_Z).value = "í•©ê³„ê¸ˆì•¡ì°¨ì´"
    else:
        ws.cell(1, col_X).value = "ê³µê¸‰ê°€ì•¡ì°¨ì´"

    last = start_row + len(df) - 1

    # â”€â”€ í–‰ë³„ë¡œ ìˆ˜ì‹ ì±„ìš°ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for row in range(start_row, last+1):
        if col_B and col_K:
            ws.cell(row, col_W).value = (
                f"=EXACT({get_column_letter(col_B)}{row},"
                f"{get_column_letter(col_K)}{row})"
            )

        if is_tax:
            if col_E and col_P:
                ws.cell(row, col_X).value = (
                    f"={get_column_letter(col_E)}{row}-"
                    f"{get_column_letter(col_P)}{row}"
                )
            if col_F and col_Q:
                ws.cell(row, col_Y).value = (
                    f"={get_column_letter(col_F)}{row}-"
                    f"{get_column_letter(col_Q)}{row}"
                )
            if col_G and col_R:
                ws.cell(row, col_Z).value = (
                    f"={get_column_letter(col_G)}{row}-"
                    f"{get_column_letter(col_R)}{row}"
                )
        else:
            if col_E and col_R:
                ws.cell(row, col_X).value = (
                    f"={get_column_letter(col_E)}{row}-"
                    f"{get_column_letter(col_R)}{row}"
                )

    # â”€â”€ ìˆ«ì ì„œì‹: ì²œ ë‹¨ìœ„ ì½¤ë§ˆ "#,##0" ì ìš© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    amount_cols = {
        col for col in [
            col_E, col_F, col_G,   # í™ˆíƒìŠ¤ ê¸ˆì•¡
            col_P, col_Q, col_R,   # í•™ì‚¬ ê¸ˆì•¡
            col_X, col_Y, col_Z    # ì°¨ì´ ê³„ì‚° ì—´
        ] if col
    }

    for col in amount_cols:
        for row in range(start_row, last+1):
            cell = ws.cell(row=row, column=col)
            if cell.value is not None:
                cell.number_format = "#,##0"

    # â”€â”€ ì—´ ë„ˆë¹„ ìë™ ë§ì¶¤ (í‘œì‹œê°’ ê¸°ì¤€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    max_col = col_Z if is_tax else col_X

    for col_idx in range(1, max_col + 1):
        col_letter = get_column_letter(col_idx)
        max_len = 0

        for row in range(1, last+1):  # í—¤ë” í¬í•¨
            cell = ws.cell(row=row, column=col_idx)
            max_len = max(max_len, display_len(cell))

        if max_len > 0:
            ws.column_dimensions[col_letter].width = max_len + 2    

    # â”€â”€ ğŸ”’ ê³µê¸‰ê°€ì•¡ì°¨ì´ ì—´ ê³ ì • í­ (105px â‰ˆ width 15) â”€â”€â”€â”€â”€â”€â”€â”€â”€
    SUPPLY_DIFF_WIDTH = 15  # 105px ì •ë„
    ws.column_dimensions[get_column_letter(col_X)].width = SUPPLY_DIFF_WIDTH            

def apply_to_all_sheets(writer, sheet_df_map, tax_sheets):
    """
    sheet_df_map: {ì‹œíŠ¸ëª…: df}
    tax_sheets: ì„¸ê¸ˆê³„ì‚°ì„œ ì‹œíŠ¸ëª… set
    """
    for sheet_name, df in sheet_df_map.items():
        is_tax = sheet_name in tax_sheets
        apply_formulas_and_autofit(
            writer=writer,
            sheet=sheet_name,
            df=df,
            is_tax=is_tax
        )

# =========================== Streamlit UI (run í•¨ìˆ˜) ===========================

def run():
    """ë©”ì¸ ì•±(app.py)ì—ì„œ ë¶ˆëŸ¬ì˜¤ëŠ” ì„¸ê¸ˆê³„ì‚°ì„œ ëŒ€ì¡° í˜ì´ì§€"""
    st.title("ğŸ§¾ í•™ì‚¬ì‹œìŠ¤í…œê³¼ í™ˆíƒìŠ¤ ì„¸ê¸ˆê³„ì‚°ì„œ ëŒ€ì¡°")

    uploaded_files = st.file_uploader(
        "ì„¸ê¸ˆê³„ì‚°ì„œ ê´€ë ¨ 8ê°œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. ex)í•™ì‚¬ë§¤ì…ì„¸ê¸ˆê³„ì‚°ì„œ, í™ˆíƒìŠ¤ë§¤ì¶œê³„ì‚°ì„œ",
        type=["xlsx", "xlsm"],
        accept_multiple_files=True,
    )
    if not uploaded_files:
        st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë§¤ì¹­ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
        return

    patterns = [
        ("í™ˆíƒìŠ¤ë§¤ì…ì„¸ê¸ˆê³„ì‚°ì„œ", 9),
        ("í•™ì‚¬ë§¤ì…ì„¸ê¸ˆê³„ì‚°ì„œ", 1),
        ("í™ˆíƒìŠ¤ë§¤ì¶œì„¸ê¸ˆê³„ì‚°ì„œ", 9),
        ("í•™ì‚¬ë§¤ì¶œì„¸ê¸ˆê³„ì‚°ì„œ", 1),
        ("í™ˆíƒìŠ¤ë§¤ì…ê³„ì‚°ì„œ", 9),
        ("í•™ì‚¬ë§¤ì…ê³„ì‚°ì„œ", 1),
        ("í™ˆíƒìŠ¤ë§¤ì¶œê³„ì‚°ì„œ", 9),
        ("í•™ì‚¬ë§¤ì¶œê³„ì‚°ì„œ", 1),
    ]

    data_map = {}
    #st.subheader("íŒŒì¼ ë¡œë”© ê²°ê³¼")
    for pat, sr in patterns:
         df, msg = import_by_pattern(uploaded_files, pat, sr)
         data_map[pat] = df
         #st.write(msg)

    # ë§¤ì¹­
    buy_tax = connect_by_id(
        data_map["í™ˆíƒìŠ¤ë§¤ì…ì„¸ê¸ˆê³„ì‚°ì„œ"], data_map["í•™ì‚¬ë§¤ì…ì„¸ê¸ˆê³„ì‚°ì„œ"]
    )
    sell_tax = connect_by_id(
        data_map["í™ˆíƒìŠ¤ë§¤ì¶œì„¸ê¸ˆê³„ì‚°ì„œ"], data_map["í•™ì‚¬ë§¤ì¶œì„¸ê¸ˆê³„ì‚°ì„œ"]
    )
    buy_bill = connect_by_id(
        data_map["í™ˆíƒìŠ¤ë§¤ì…ê³„ì‚°ì„œ"], data_map["í•™ì‚¬ë§¤ì…ê³„ì‚°ì„œ"]
    )
    sell_bill = connect_by_id(
        data_map["í™ˆíƒìŠ¤ë§¤ì¶œê³„ì‚°ì„œ"], data_map["í•™ì‚¬ë§¤ì¶œê³„ì‚°ì„œ"]
    )

    # ë§¤ì… â†’ ë§¤ì¶œ êµ¬ì¡° ë§ì¶”ê¸°
    buy_tax = align_columns(sell_tax, buy_tax)
    buy_bill = align_columns(sell_bill, buy_bill)

    # ë§¤ì… ì „ìš© ì •ë¦¬ + ê³µí†µ ì •ë¦¬
    buy_tax = clean_buy_df(buy_tax)
    buy_tax = clean_common_df(buy_tax)
    buy_tax = reorder_haksa_vendor(buy_tax)

    buy_bill = clean_buy_df(buy_bill)
    buy_bill = clean_common_df(buy_bill)
    buy_bill = reorder_haksa_vendor(buy_bill)

    # ë§¤ì¶œ ê³µí†µ ì •ë¦¬
    sell_tax = clean_common_df(sell_tax)
    sell_tax = reorder_haksa_vendor(sell_tax)

    sell_bill = clean_common_df(sell_bill)
    sell_bill = reorder_haksa_vendor(sell_bill)

    # ë¯¸ë¦¬ë³´ê¸°
    # st.subheader("ë¯¸ë¦¬ë³´ê¸°")
    # col1, col2 = st.columns(2)
    # with col1:
    #     st.caption("ë§¤ì…ì„¸ê¸ˆê³„ì‚°ì„œ")
    #     st.dataframe(buy_tax.head())
    #     st.caption("ë§¤ì…ê³„ì‚°ì„œ")
    #     st.dataframe(buy_bill.head())
    # with col2:
    #     st.caption("ë§¤ì¶œì„¸ê¸ˆê³„ì‚°ì„œ")
    #     st.dataframe(sell_tax.head())
    #     st.caption("ë§¤ì¶œê³„ì‚°ì„œ")
    #     st.dataframe(sell_bill.head())

    # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
    st.subheader("í†µí•© ì—‘ì…€ ë‹¤ìš´ë¡œë“œ")
    if st.button("ğŸ“¥ ëŒ€ì¡°ê²°ê³¼ ì—‘ì…€ ìƒì„±"):
        output = BytesIO()

        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            sheet_map = {
                "ë§¤ì…ì„¸ê¸ˆê³„ì‚°ì„œ_ë§¤ì¹­": (buy_tax, True),
                "ë§¤ì¶œì„¸ê¸ˆê³„ì‚°ì„œ_ë§¤ì¹­": (sell_tax, True),
                "ë§¤ì…ê³„ì‚°ì„œ_ë§¤ì¹­":     (buy_bill, False),
                "ë§¤ì¶œê³„ì‚°ì„œ_ë§¤ì¹­":     (sell_bill, False),
            }

            for sheet_name, (df, is_tax) in sheet_map.items():
                df.to_excel(writer, sheet_name=sheet_name, index=False)
                apply_formulas_and_autofit(
                    writer=writer,
                    sheet=sheet_name,
                    df=df,
                    is_tax=is_tax
                )

        output.seek(0)
        st.download_button(
            "ğŸ“— ëŒ€ì¡°ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            output,
            file_name="ì„¸ê¸ˆê³„ì‚°ì„œ_í†µí•©.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
